# Finding and fitting interactions

When we train decision trees, random forests, or gradient boosting trees, or neural networks, they automatically find interactions for us (even if it is not totally straightforward to actually find out what they are). In fact, some time back, a certain type of decision tree was known as CHAID - a CHi-squared Automatic Interaction Detector.

When we train GLMs they do not automatically find interactions for us.

Thus, a price for the transparency of the GLM is that we need to find (and code up) interactions (if there are any).

The approach we take here is to first find and propose candidate interaction pairs and then, for each candidate, to code it up as a feature for our GLM and finally to fit it. Interactions which improve CV performance and seem sensible for the domain we are working in, are likely to end up in our final model.

-   Domain knowledge. policyjolder age x vehicle accelaration (0-60)
-   Learning from black-box models
-   MARS
